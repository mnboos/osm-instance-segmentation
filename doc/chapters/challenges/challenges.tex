% !TeX spellcheck = en_US

\chapter{Theoretical and Practical Challenges}

\section{Training data generation}
In order to train the neural network a data set was required, which could then be used for training and validation. Due to this, a tool \cite{airtiler} has been developed which uses publicly available vector data from OpenStreetMap and satellite imagery Microsoft Bing.

tbd

\section{Building outline regularization}
Once the network has been trained, it can be used to make predictions on images, it has never "seen" before. However, there are situations in which the predictions are far from perfect, especially then if the building is partially covered from trees or has unclear outlines. This can be seen in \autoref{fig:challenges:building_masks}.

\begin{figure}[H]
	\centering
	\begin{subfigure}{0.4\textwidth}
		\centering
    	\includegraphics[width=0.9\linewidth]{chapters/challenges/images/predicted_masks_gt.png}		    \caption{Actual ground truth}
    	\label{fig:challenges:predicted_building_masks_gt}
	\end{subfigure}~
		\begin{subfigure}{0.4\textwidth}
		\centering
    	\includegraphics[width=0.9\linewidth]{chapters/challenges/images/predicted_masks.png}		    \caption{Predicted building masks}
    	\label{fig:challenges:predicted_building_masks}
	\end{subfigure}
	\caption{Predicted masks and actual ground truth}
	\label{fig:challenges:building_masks}
\end{figure}

As a result of the inaccuracies in the predicted building masks the contours of these predictions can not directly be used to create the vectorized outlines. Instead, the predictions have to be regularized. The approach used is similar to \cite{Partovi.2017} and described in \autoref{fig:challenges:rectangularization}.

\begin{figure}[H]
\centering
\begin{tikzpicture}[node distance = 2cm, auto, scale=0.7, every node/.style={transform shape}]
    % Place nodes
    \node [cloud] (mask) {Predicted mask};
    \node [block, below of=mask] (extract_contour) {Extract contour};
    \node [cloud, below of=extract_contour] (contour) {Approximated contour};
    \node [block, below of=contour] (segment) {Line segmentation};
    \node [cloud, below of=segment] (line_segments) {Line segments};
    \node [block, below of=line_segments] (assign_orientation) {Create orientation classes};
    \node [block, below of=assign_orientation] (assign_neighbourhoods) {Create neighbourhoods};
    \node [block, below of=assign_neighbourhoods] (rotate_lines) {Rotate lines};
    \node [block, below of=rotate_lines] (gap_filling) {Gap filling};
    \node [cloud, below of=gap_filling] (corner_points) {Building corner points};

    % Draw edges
    \path [line,dashed] (mask) -- (extract_contour);
    \path [line,dashed] (extract_contour) -- (contour);
    \path [line,dashed] (contour) -- (segment);
    \path [line,dashed] (segment) -- (line_segments);
    \path [line,dashed] (line_segments) -- (assign_orientation);
    \path [line] (assign_orientation) -- (assign_neighbourhoods);
    \path [line] (assign_neighbourhoods) -- (rotate_lines);
    \path [line] (rotate_lines) -- (gap_filling);
    \path [line,dashed] (gap_filling) -- (corner_points);
\end{tikzpicture}
	\caption{Rectangularization procedure}
	\label{fig:challenges:rectangularization}
\end{figure}

The single steps are described in detail in the following sections.

\subsection{Contour extraction}
The first step of the building outline regularization procedure consists of getting the contour from the predicted mask, which covers the whole building. The extraction is done using the marching squares algorithm \cite{Maple.2003}. In this algorithm, a square consisting of four cells is moved (marched) along the contour in such a way, that at least one cell always covers the object to be contoured. Additionally, the square always has a state, which is derived from the content of its cells, according to \eqref{equ:challenges:marching_squares_state}. The cells are traversed in counter clockwise order.

\newenvironment{conditions}
  {\par\vspace{\abovedisplayskip}\noindent\begin{tabular}{>{$}l<{$} @{${}={}$} l}}
  {\end{tabular}\par\vspace{\belowdisplayskip}}

\begin{equation}
\begin{split}
	s	&= \displaystyle\sum_{i=0}^3 2^i f(c_i) \\
		&= 2^0 * f(c_0) + 2^1 * f(c_1) + 2^2 * f(c_2) + 2^3 * f(c_3) \\
		&= f(c_{bottomLeft}) + 2 * f(c_{bottomRight}) + 4 * f(c_{topRight}) + 8 * f(c_{topLeft})
	\label{equ:challenges:marching_squares_state}
\end{split}
\end{equation}
where:
\begin{itemize}[label=]
    \item $c_i$: The value of the cell $i$
    \item $c_0$: The bottom left cell
\end{itemize}

and

\[ f(c_i) =
  \begin{cases}
    0  & \text{if $c_i \leq 0$}\\
    1  & \text{if $c_i > 0$}
  \end{cases}
\]


As soon as the contour has been extracted, its number of points will be reduced using a Douglas-Peucker algorithm \cite{DOUGLAS.1973}. The reason for this is, that the contour has pixel accuracy. That means, there may be several points on the same horizontal or vertical line, even though, the startpoint and endpoint of each such line would be enough, to represent the line. Additionally, the lower the number of points per contour is, the faster the following processing will be.

\begin{figure}[H]
    \centering
	\begin{subfigure}{0.4\textwidth}
    	\includegraphics[width=0.9\linewidth]{chapters/challenges/images/original_contour.png}		    	\caption{Original contour}
	\end{subfigure}~
	\begin{subfigure}{0.4\textwidth}
    	\includegraphics[width=0.9\linewidth]{chapters/challenges/images/approx_contour.png}       			\caption{Approximated contour}
	\end{subfigure}
	\caption{Contour before and after approximation}
	\label{fig:challenges:contour_approximation}
\end{figure}


\subsection{Line segmentation}
Once the contour has been extracted, it is split into multiple line segments. For this, the main direction of the building is determined using the Hough lines algorithm. The result of this is the line which hits the greatest number of points. The angle between this line and a horizontal line gives the main building orientation.

Once the main building direction is known, the line segmentation starts at the point which has the smallest distance to this line. The whole procedure is depicted in \autoref{alg:challenges:line_segmentation}.

\begin{algorithm}[H]
\KwData{Contour points, startpoint}
\KwResult{Lines}
rearrange points so that startpoint == points[0]\\
lines = []\\
\While{any points left}{
	segment = remove first 3 elements from points\\
	\While{points is not empty}{
		p = points.first()\\
		err = root mean square error of distance between segment.last() and p\\
		\If{err > threshold}{
			break
		}
		segment.append(p)\\
		points.remove(p)\\
	}
	\If{segment.length() >= 3}{
		line = fit line to points of segment\\
		lines.append(line)
	}
}
\caption{Line segmentation}
\label{alg:challenges:line_segmentation}
\end{algorithm}

\subsection{Create orientation classes}
After the line segmentation, an orientation will be assigned to each line. Generally, most of the buildings consist of mainly right angles. However, there are still buildings, for which this assumption is not true. Due to this, orthogonality will be preferred, but other angles will still be possible. Algorithm~\ref{alg:challenges:define_orientations} shows the procedure, which assigns a main orientation class to each line and defines the lines parallelity / orthogonality to the longest line of the same orientation class.

\begin{figure}[H]
    \centering
	\begin{subfigure}{0.4\textwidth}
    	\includegraphics[width=0.9\linewidth]{chapters/challenges/images/regular_building_masks.png}		    \caption{Regular buildings}
    	\label{fig:challenges:regular_buildings}
	\end{subfigure}~
	\begin{subfigure}{0.4\textwidth}
    	\includegraphics[width=0.9\linewidth]{chapters/challenges/images/irregular_building_masks.png}       	\caption{Non-orthogonal buildings}
    	\label{fig:challenges:irregular_buildings}
	\end{subfigure}
	\caption{Different kinds of buildings with regard to their corner angles}
	\label{fig:challenges:building_ground_truths}
\end{figure}

\begin{algorithm}[H]
\KwData{Lines, angleThreshold}
	\While{any line without orientation}{
		line = longest of unprocessed lines\\
		line.orientation = angle between line and horizontal-line \\
		\ForEach{line li without orientation}{
			a = angle between line and li\\
			\If{a $\leq$ angleThreshold}{
				li.orientation = line.orientation
				li.orthogonal = line.orthogonalTo(line)
			}
		}
	}
\caption{Orientation assignment}
\label{alg:challenges:define_orientations}
\end{algorithm}

\subsection{Create neighbourhoods}
At this point, each line segment belongs to a orientation class and the parallelity / orthogonality of each line to the orientation classes main line is known. However, the spatial location of each line has not been taken into account yet, which is done in this step. Clusters of neighbouring lines are created within each orientation class. As a result of this, it is now possible to find lines, which may be better placed in an other orientation class. This is based in the assumption, that it is unprobable, that a line $k$ of the orientation class $x$ is surrounded by lines of the orientation class $y$. In this case, the line $k$ will be assigned to the orientation class $y$.

\subsection{Update line orientation}
Finally, the lines will be adjusted to their orientation class with respect to each lines parallelity / orthogonality. The result of such an adjustment, can be seen in \autoref{fig:challenges:adjusted_lines}, which shows a single orientation class and lines, which have been adjusted either parallel or orthogonal to the orientation class.

\begin{figure}[H]
    \centering
	\includegraphics[width=0.4\linewidth]{chapters/challenges/images/adjusted_lines.png}
	\caption{Adjusted lines}
	\label{fig:challenges:adjusted_lines}
\end{figure}

\subsection{Gap filling}
In order to create the final building outline, the only thing left to do is to fill the gaps between the line segments.

\begin{figure}[H]
    \centering
	\includegraphics[width=0.4\linewidth]{chapters/challenges/images/filled_gaps.png}
	\caption{Final building outline}
	\label{fig:challenges:final_building_outline}
\end{figure}